{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1poT-tpUWgo4"
   },
   "source": [
    "Mount Google Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxG3aEmhWiV4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHYT0wwCWjlN"
   },
   "source": [
    "# **Lab 2 : Decision Tree and Random Forest**\n",
    "In *lab 2*, you need to finish :\n",
    "\n",
    "1. Basic Part :\n",
    "  Implement a Decision Tree model and predict whether patients in the validation set survived.\n",
    "\n",
    "  > * Section 1: Function Implementation and Testing\n",
    "  > * Section 2: Building the Decision Tree Model\n",
    "\n",
    "\n",
    "2. Advanced Part : Build a **Random Forest** model to make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtkN1RNQKznC"
   },
   "source": [
    "❗ **Important** ❗\n",
    "Please follow the template. Follow the instructions.\n",
    "**Do not** change the code outside this code bracket if you see one.\n",
    "```\n",
    "### START CODE HERE ###\n",
    "...\n",
    "### END CODE HERE ###\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViMa9pPp0L8U"
   },
   "source": [
    "We'll be using **pandas** frequently in this template, so we've provided a link to help you get familiar with its usage: https://pandas.pydata.org/docs/user_guide/10min.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBzqwVcaWqll"
   },
   "source": [
    "## Import Packages\n",
    "\n",
    "> Note : You **cannot** import any other packages in both basic and advanced part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eb6ccSWDWrTd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from numpy import sqrt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHwMS_7dWtwj"
   },
   "source": [
    "# **Basic Part** (30%)\n",
    "\n",
    "## Section 1: Function Implementation and Testing\n",
    "You will implement five functions that are necessary for building a decision tree model. After implementing each function, you must run it with the given input variables to verify its correctness. Save the results of each function to a CSV file for submission.\n",
    "> * Step 1: Calculate the Entropy\n",
    "> * Step 2: Calculate the Information Gain\n",
    "> * Step 3: Find the Best Split\n",
    "> * Step 4: Split the data into two branches\n",
    "> * Step 5: Build the decision tree\n",
    "> * Step 6: Save answers\n",
    "\n",
    "\n",
    "## Section 2: Build a Decision Tree Model and make Predictions\n",
    "After implementing the functions, you will use them to build a decision tree model and make predictions. Follow the steps below to train your model and evaluate its performance.\n",
    "> * Step 1: Split the data into training set and validation set\n",
    "> * Step 2: Train a decision tree model with the training set\n",
    "> * Step 3: Predict the cases in the validation set by using the model trained in Step 2\n",
    "> * Step 4: Calculate the f1-score of your predictions in Step 3\n",
    "> * Step 5: Save answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeEPi9tfWzx_"
   },
   "source": [
    "## Load the input data\n",
    "Let's load the input file **lab2_basic_input.csv**.\n",
    "\n",
    "> Note: you will use this input data in both section 1 and section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TIOE-YsHW3lA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>pre_icu_los_days</th>\n",
       "      <th>glucose_apache</th>\n",
       "      <th>heart_rate_apache</th>\n",
       "      <th>resprate_apache</th>\n",
       "      <th>sodium_apache</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>26.596278</td>\n",
       "      <td>1</td>\n",
       "      <td>173.0</td>\n",
       "      <td>79.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>36.267895</td>\n",
       "      <td>0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>117.90</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>24.196007</td>\n",
       "      <td>1</td>\n",
       "      <td>162.0</td>\n",
       "      <td>63.50</td>\n",
       "      <td>1.988194</td>\n",
       "      <td>285.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.0</td>\n",
       "      <td>21.105377</td>\n",
       "      <td>1</td>\n",
       "      <td>162.6</td>\n",
       "      <td>55.80</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>189.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>20.470093</td>\n",
       "      <td>0</td>\n",
       "      <td>167.6</td>\n",
       "      <td>57.50</td>\n",
       "      <td>14.493056</td>\n",
       "      <td>278.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.0</td>\n",
       "      <td>46.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>149.40</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>186.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70.0</td>\n",
       "      <td>17.361111</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.156944</td>\n",
       "      <td>181.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79.0</td>\n",
       "      <td>33.274623</td>\n",
       "      <td>0</td>\n",
       "      <td>165.1</td>\n",
       "      <td>90.70</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81.0</td>\n",
       "      <td>30.462306</td>\n",
       "      <td>0</td>\n",
       "      <td>177.8</td>\n",
       "      <td>96.30</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>113.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.0</td>\n",
       "      <td>25.843929</td>\n",
       "      <td>0</td>\n",
       "      <td>177.8</td>\n",
       "      <td>81.70</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>112.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54.0</td>\n",
       "      <td>35.008738</td>\n",
       "      <td>1</td>\n",
       "      <td>154.9</td>\n",
       "      <td>84.00</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55.0</td>\n",
       "      <td>28.697484</td>\n",
       "      <td>0</td>\n",
       "      <td>182.9</td>\n",
       "      <td>96.00</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>88.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65.0</td>\n",
       "      <td>15.741828</td>\n",
       "      <td>1</td>\n",
       "      <td>157.4</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0.099306</td>\n",
       "      <td>92.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68.0</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>1</td>\n",
       "      <td>165.1</td>\n",
       "      <td>75.70</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>211.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81.0</td>\n",
       "      <td>21.575208</td>\n",
       "      <td>1</td>\n",
       "      <td>157.5</td>\n",
       "      <td>53.52</td>\n",
       "      <td>3.043056</td>\n",
       "      <td>90.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>67.0</td>\n",
       "      <td>30.506023</td>\n",
       "      <td>0</td>\n",
       "      <td>182.9</td>\n",
       "      <td>102.05</td>\n",
       "      <td>0.350694</td>\n",
       "      <td>107.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>77.0</td>\n",
       "      <td>25.827736</td>\n",
       "      <td>0</td>\n",
       "      <td>182.9</td>\n",
       "      <td>86.40</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>69.0</td>\n",
       "      <td>23.397612</td>\n",
       "      <td>1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>63.70</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>224.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77.0</td>\n",
       "      <td>34.532872</td>\n",
       "      <td>1</td>\n",
       "      <td>170.0</td>\n",
       "      <td>99.80</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>250.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64.0</td>\n",
       "      <td>27.394313</td>\n",
       "      <td>1</td>\n",
       "      <td>167.0</td>\n",
       "      <td>76.40</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>373.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>51.0</td>\n",
       "      <td>28.219692</td>\n",
       "      <td>0</td>\n",
       "      <td>185.4</td>\n",
       "      <td>97.00</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>90.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>62.0</td>\n",
       "      <td>23.640816</td>\n",
       "      <td>0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>72.40</td>\n",
       "      <td>6.063889</td>\n",
       "      <td>202.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54.0</td>\n",
       "      <td>34.710158</td>\n",
       "      <td>1</td>\n",
       "      <td>167.6</td>\n",
       "      <td>97.50</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>205.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74.0</td>\n",
       "      <td>33.651380</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>98.40</td>\n",
       "      <td>1.059722</td>\n",
       "      <td>184.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>52.0</td>\n",
       "      <td>20.402893</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>63.20</td>\n",
       "      <td>13.668750</td>\n",
       "      <td>105.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>70.0</td>\n",
       "      <td>28.686787</td>\n",
       "      <td>1</td>\n",
       "      <td>170.2</td>\n",
       "      <td>83.10</td>\n",
       "      <td>0.167361</td>\n",
       "      <td>201.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78.0</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>54.40</td>\n",
       "      <td>0.271528</td>\n",
       "      <td>201.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>86.0</td>\n",
       "      <td>19.188698</td>\n",
       "      <td>0</td>\n",
       "      <td>185.6</td>\n",
       "      <td>66.10</td>\n",
       "      <td>0.786111</td>\n",
       "      <td>111.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>58.0</td>\n",
       "      <td>23.295905</td>\n",
       "      <td>1</td>\n",
       "      <td>165.1</td>\n",
       "      <td>63.50</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>264.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>69.0</td>\n",
       "      <td>51.288336</td>\n",
       "      <td>1</td>\n",
       "      <td>162.6</td>\n",
       "      <td>135.60</td>\n",
       "      <td>7.174306</td>\n",
       "      <td>158.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>78.0</td>\n",
       "      <td>30.524099</td>\n",
       "      <td>0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.173611</td>\n",
       "      <td>230.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>46.0</td>\n",
       "      <td>47.477519</td>\n",
       "      <td>1</td>\n",
       "      <td>162.0</td>\n",
       "      <td>124.60</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>598.7</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63.0</td>\n",
       "      <td>28.138070</td>\n",
       "      <td>1</td>\n",
       "      <td>157.5</td>\n",
       "      <td>69.80</td>\n",
       "      <td>0.809028</td>\n",
       "      <td>105.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32.0</td>\n",
       "      <td>20.012958</td>\n",
       "      <td>0</td>\n",
       "      <td>175.3</td>\n",
       "      <td>61.50</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>573.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>76.0</td>\n",
       "      <td>31.265432</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>101.30</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>102.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>72.0</td>\n",
       "      <td>21.165166</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>48.90</td>\n",
       "      <td>0.268056</td>\n",
       "      <td>103.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>43.0</td>\n",
       "      <td>31.294766</td>\n",
       "      <td>1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>85.20</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>93.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>57.0</td>\n",
       "      <td>31.757926</td>\n",
       "      <td>1</td>\n",
       "      <td>154.9</td>\n",
       "      <td>76.20</td>\n",
       "      <td>2.721528</td>\n",
       "      <td>181.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>31.0</td>\n",
       "      <td>37.300976</td>\n",
       "      <td>1</td>\n",
       "      <td>154.9</td>\n",
       "      <td>89.50</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>75.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>81.0</td>\n",
       "      <td>20.989855</td>\n",
       "      <td>0</td>\n",
       "      <td>167.6</td>\n",
       "      <td>58.96</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>212.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age        bmi  gender  height  weight  pre_icu_los_days  glucose_apache  \\\n",
       "0   28.0  26.596278       1   173.0   79.60          0.000000           199.0   \n",
       "1   51.0  36.267895       0   180.3  117.90          0.141667            88.0   \n",
       "2   81.0  24.196007       1   162.0   63.50          1.988194           285.0   \n",
       "3   83.0  21.105377       1   162.6   55.80          0.211111           189.0   \n",
       "4   76.0  20.470093       0   167.6   57.50         14.493056           278.0   \n",
       "5   60.0  46.111111       0   180.0  149.40          0.027778           186.0   \n",
       "6   70.0  17.361111       1   168.0   49.00          0.156944           181.0   \n",
       "7   79.0  33.274623       0   165.1   90.70          0.004861            56.0   \n",
       "8   81.0  30.462306       0   177.8   96.30          0.002083           113.0   \n",
       "9   54.0  25.843929       0   177.8   81.70          0.007639           112.0   \n",
       "10  54.0  35.008738       1   154.9   84.00          0.702083            89.0   \n",
       "11  55.0  28.697484       0   182.9   96.00          0.048611            88.0   \n",
       "12  65.0  15.741828       1   157.4   39.00          0.099306            92.0   \n",
       "13  68.0  27.771653       1   165.1   75.70          0.015278           211.0   \n",
       "14  81.0  21.575208       1   157.5   53.52          3.043056            90.0   \n",
       "15  67.0  30.506023       0   182.9  102.05          0.350694           107.0   \n",
       "16  77.0  25.827736       0   182.9   86.40          0.712500            97.0   \n",
       "17  69.0  23.397612       1   165.0   63.70          0.035417           224.0   \n",
       "18  77.0  34.532872       1   170.0   99.80          0.035417           250.0   \n",
       "19  64.0  27.394313       1   167.0   76.40          0.011111           373.0   \n",
       "20  51.0  28.219692       0   185.4   97.00          0.537500            90.0   \n",
       "21  62.0  23.640816       0   175.0   72.40          6.063889           202.0   \n",
       "22  54.0  34.710158       1   167.6   97.50          0.044444           205.0   \n",
       "23  74.0  33.651380       0   171.0   98.40          1.059722           184.0   \n",
       "24  52.0  20.402893       0   176.0   63.20         13.668750           105.0   \n",
       "25  70.0  28.686787       1   170.2   83.10          0.167361           201.0   \n",
       "26  78.0  21.250000       1   160.0   54.40          0.271528           201.0   \n",
       "27  86.0  19.188698       0   185.6   66.10          0.786111           111.0   \n",
       "28  58.0  23.295905       1   165.1   63.50          0.001389           264.0   \n",
       "29  69.0  51.288336       1   162.6  135.60          7.174306           158.0   \n",
       "30  78.0  30.524099       0   181.0  100.00          0.173611           230.0   \n",
       "31  46.0  47.477519       1   162.0  124.60          0.000694           598.7   \n",
       "32  63.0  28.138070       1   157.5   69.80          0.809028           105.0   \n",
       "33  32.0  20.012958       0   175.3   61.50          0.004861           573.0   \n",
       "34  76.0  31.265432       0   180.0  101.30          0.077778           102.0   \n",
       "35  72.0  21.165166       1   152.0   48.90          0.268056           103.0   \n",
       "36  43.0  31.294766       1   165.0   85.20          0.083333            93.0   \n",
       "37  57.0  31.757926       1   154.9   76.20          2.721528           181.0   \n",
       "38  31.0  37.300976       1   154.9   89.50          0.423611            75.0   \n",
       "39  81.0  20.989855       0   167.6   58.96          0.131250           212.0   \n",
       "\n",
       "    heart_rate_apache  resprate_apache  sodium_apache  hospital_death  \n",
       "0                52.0             29.0          140.0               0  \n",
       "1               104.0             31.0          143.0               0  \n",
       "2               178.0              4.0          138.0               1  \n",
       "3               115.0             18.0          158.0               0  \n",
       "4                93.0              8.0          134.0               1  \n",
       "5               146.0             34.0          139.0               1  \n",
       "6               111.0             12.0          158.0               1  \n",
       "7                37.0             44.0          141.0               0  \n",
       "8                62.0              4.0          142.0               0  \n",
       "9               110.0             24.0          136.0               1  \n",
       "10              105.0             37.0          144.0               0  \n",
       "11              115.0             33.0          138.0               0  \n",
       "12               58.0              8.0          121.0               0  \n",
       "13              104.0              4.0          128.0               1  \n",
       "14               99.0              8.0          136.0               0  \n",
       "15              105.0             11.0          149.0               1  \n",
       "16               92.0             18.0          139.0               0  \n",
       "17               90.0             37.0          137.0               1  \n",
       "18              116.0             11.0          141.0               1  \n",
       "19              141.0             31.0          139.0               1  \n",
       "20              146.0             45.0          132.0               1  \n",
       "21               52.0             12.0          129.0               1  \n",
       "22              110.0             52.0          137.0               0  \n",
       "23              103.0              4.0          136.0               0  \n",
       "24              133.0             44.0          135.0               1  \n",
       "25               95.0             25.0          139.0               1  \n",
       "26              134.0             60.0          130.0               0  \n",
       "27              152.0             30.0          137.0               1  \n",
       "28              178.0             40.0          139.0               1  \n",
       "29              154.0             45.0          138.0               1  \n",
       "30               98.0              9.0          132.0               1  \n",
       "31               39.0             12.0          130.0               1  \n",
       "32               99.0              6.0          138.0               0  \n",
       "33              107.0              7.0          140.0               0  \n",
       "34              124.0              6.0          150.0               1  \n",
       "35              130.0             31.0          147.0               1  \n",
       "36              122.0             10.0          144.0               0  \n",
       "37              137.0             47.0          141.0               1  \n",
       "38              116.0             42.0          139.0               0  \n",
       "39              138.0             12.0          154.0               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_csv('lab2_basic_input.csv')\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cdYaIEjW7-r"
   },
   "source": [
    "## Global attributes\n",
    "Define the global attributes\n",
    "> Note : You **cannot** modify the values of these attributes we have provided in the basic part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "S4WLhABvW6Qr"
   },
   "outputs": [],
   "source": [
    "max_depth = 2\n",
    "depth = 0\n",
    "min_samples_split = 2\n",
    "n_features = input_data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zxs3U-K2W-ZI"
   },
   "source": [
    "> You can add your own global attributes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6x_2G6hNXA1_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qvPkvOpXBgX"
   },
   "source": [
    "## Section 1: Function Implementation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WWTmDqyXGR5"
   },
   "source": [
    "### Step 1 & 2: Calculate the Entropy and Information Gain\n",
    "In these steps, you will implement functions to calculate entropy and information gain. These metrics are crucial for determining the best way to split the dataset at each node in the decision tree.\n",
    "\n",
    "If you need some help on Entropy and Information Gain, please refer to\n",
    "* https://codingnomads.com/decision-tree-information-gain-entropy#what-is-entropy\n",
    "* https://www.mldawn.com/decision-trees-entropy/#:~:text=In%20a%20binary%20classification%20problem%2C%20when%20Entropy%20hits%200%20it,state%20of%20purity%20and%20certainty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4j-LodsRXLd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_entropy =  0.9928\n"
     ]
    }
   ],
   "source": [
    "def entropy(data):\n",
    "    \"\"\"\n",
    "    This function measures the amount of uncertainty in a probability distribution\n",
    "    args:\n",
    "    * data(type: DataFrame): the data you're calculating for the entropy\n",
    "    return:\n",
    "    * entropy_value(type: float): the data's entropy\n",
    "    \"\"\"\n",
    "    p = 0 # to count the number of cases that survived\n",
    "    n = 0 # to count the number of cases that passed away\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Hint 1: what is the equation for calculating entropy?\n",
    "    # Hint 2: consider the case when p == 0 or n == 0, what should entropy be?\n",
    "    entropy_value = 0\n",
    "    dct = data['hospital_death'].value_counts().to_dict()\n",
    "    if (0 not in dct.keys()) or (1 not in dct.keys()):\n",
    "        entropy_value = 0\n",
    "    else:   \n",
    "        p = dct[0]/len(data)\n",
    "        n = dct[1]/len(data)\n",
    "        entropy_value = -p * np.log2(p) - n * np.log2(n)\n",
    "        entropy_value = round(entropy_value, 4)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return entropy_value\n",
    "\n",
    "# [Note] You have to save the value of \"ans_entropy\" into the output file\n",
    "# Please round your answer to 4 decimal place\n",
    "ans_entropy = entropy(input_data)\n",
    "print(\"ans_entropy = \", ans_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6pZ-HjJiDWv"
   },
   "source": [
    "Expected output:\n",
    "> ans_entropy =  0.9928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hTvkGOCdXS0H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_informationGain =  0.0385\n"
     ]
    }
   ],
   "source": [
    "def information_gain(data, mask):\n",
    "    \"\"\"\n",
    "    This function will calculate the information gain\n",
    "    args:\n",
    "    * data(type: DataFrame): the data you're calculating for the information gain\n",
    "    * mask(type: Series): partition information(left/right) of current input data,\n",
    "    - boolean 1(True) represents split to left subtree\n",
    "    - boolean 0(False) represents split to right subtree\n",
    "    return:\n",
    "    * ig(type: float): the information gain you can obtain by classifying the data with this given mask\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    # Hint: you should use mask to split the data into two, then recall what is the equation for calculating information gain\n",
    "    left = data[mask]\n",
    "    right = data[~mask]\n",
    "    parent_entropy = entropy(data)\n",
    "    left_entropy = entropy(left)\n",
    "    right_entropy = entropy(right)\n",
    "    ig = parent_entropy - ((len(left)/len(data) * left_entropy) + (len(right)/len(data) * right_entropy))\n",
    "    ig = round(ig, 4)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return ig\n",
    "\n",
    "# [Note] You have to save the value of \"ans_informationGain\" into your output file\n",
    "# Here, let's assume that we split the input_data with 2/3 of the data in the left subtree and 1/3 in the right subtree\n",
    "# Please round your answer to 4 decimal place\n",
    "temp1 = np.zeros((int(input_data.shape[0]/3), 1), dtype=bool)\n",
    "temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/3), 1)), dtype=bool)\n",
    "temp_mask = np.concatenate((temp1, temp2))\n",
    "df_mask = pd.DataFrame(temp_mask, columns=['mask'])\n",
    "ans_informationGain = information_gain(input_data, df_mask['mask'])\n",
    "print(\"ans_informationGain = \", ans_informationGain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5RLtCwcieQ8"
   },
   "source": [
    "Expected output:\n",
    "> ans_informationGain = 0.0385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXajOk9jXefG"
   },
   "source": [
    "### Step 3: Find the Best Split\n",
    "In this step, you will use the information gain calculated for each feature to find the best split. The best split is the point where the dataset is divided into two subgroups (left and right subtrees) in a way that maximizes the reduction of entropy.\n",
    "\n",
    "\n",
    "> Method: The process involves evaluating **every possible split** for each feature in the dataset. After sorting the data, you calculate potential split points by taking the **median of two consecutive values** where they differ. This median value becomes the threshold for splitting the data into two branches. The split that results in the highest information gain is selected as the best split.\n",
    "\n",
    "> Note: The method we have provided is a straightforward and basic approach. Please use this method to complete the basic part of the assignment. However, for the advanced part, you are welcome to explore and use other methods to fine-tune your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oT8UOEtzXiEu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_ig =  0.2146\n",
      "ans_value =  99.5\n",
      "ans_name =  glucose_apache\n"
     ]
    }
   ],
   "source": [
    "def find_best_split(data, impl_part):\n",
    "    \"\"\"\n",
    "    This function will find the best split combination of data\n",
    "    args:\n",
    "    * data(type: DataFrame): the input data\n",
    "    * impl_part(type: string): 'basic' or 'advanced' to specify which implementation to use\n",
    "    return\n",
    "    * best_ig(type: float): the best information gain you obtain\n",
    "    * best_threshold(type: float): the value that splits data into 2 branches\n",
    "    * best_feature(type: string): the feature that splits data into 2 branches\n",
    "    \"\"\"\n",
    "    best_ig = -1e9\n",
    "    best_threshold = 0\n",
    "    best_feature = ''\n",
    "\n",
    "    if(impl_part == 'basic'):\n",
    "    # Implement this part of the function using the method we provided\n",
    "    ### START CODE HERE ###\n",
    "        for i in data:\n",
    "            if i != 'gender' and i != 'hospital_death':\n",
    "                temp_data = data.sort_values(by=[i]).reset_index(drop=True)\n",
    "                #print(temp_data)\n",
    "                for j in range(len(temp_data[i])-1):\n",
    "                    if temp_data[i].iloc[j] == temp_data[i].iloc[j+1]:\n",
    "                        continue\n",
    "                    mid = (temp_data[i].iloc[j] + temp_data[i].iloc[j+1])/2\n",
    "                    mask = temp_data[i] > mid\n",
    "                    ig = information_gain(temp_data, mask)\n",
    "                    #print(ig, mid)\n",
    "                    if ig > best_ig:\n",
    "                        best_ig = ig\n",
    "                        best_threshold = mid\n",
    "                        best_feature = i\n",
    "            if i == 'gender':\n",
    "                mask = (data[i] == 0)\n",
    "                ig = information_gain(data, mask)\n",
    "                if ig > best_ig:\n",
    "                    best_ig = ig\n",
    "                    best_threshold = 0\n",
    "                    best_feature = i\n",
    "                mask = (data[i] == 1)\n",
    "                ig = information_gain(data, mask)\n",
    "                if ig > best_ig:\n",
    "                    best_ig = ig\n",
    "                    best_threshold = 1\n",
    "                    best_feature = i\n",
    "            #print(best_ig, best_threshold, best_feature)\n",
    "                \n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    else:\n",
    "    # You can implement another method here for the advanced part\n",
    "    ### START CODE HERE ###\n",
    "        pass\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "\n",
    "    return best_ig, best_threshold, best_feature\n",
    "\n",
    "\n",
    "# [Note] You have to save the value of \"ans_ig\", \"ans_value\", and \"ans_name\" into the output file\n",
    "# Here, let's try to find the best split for the input_data\n",
    "# Please round your answer to 4 decimal place\n",
    "ans_ig, ans_value, ans_name = find_best_split(input_data, 'basic')\n",
    "print(\"ans_ig = \", ans_ig)\n",
    "print(\"ans_value = \", ans_value)\n",
    "print(\"ans_name = \", ans_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovN6pxbXjQE6"
   },
   "source": [
    "Expected output:\n",
    "> ans_ig =  0.2146\n",
    "\n",
    "> ans_value =  99.5\n",
    "\n",
    "> ans_name =  glucose_apache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6koURsiXwjm"
   },
   "source": [
    "### Step 4: Split into 2 branches\n",
    "\n",
    "When you are building a decision tree, after identifying the best split, you will divide the dataset into two branches: a left branch and a right branch. Each branch represents a subset of the data based on the chosen **feature** and **split point**.\n",
    "\n",
    "* The left branch will contain the data points that meet the condition of the split (e.g., values less than or equal to the split threshold).\n",
    "* The right branch will contain the remaining data points (e.g., values greater than the split threshold).\n",
    "\n",
    "This step is essential because it creates the subgroups that the decision tree will continue to split in subsequent steps. By repeatedly splitting the data into smaller and more homogenous branches, the tree becomes more capable of accurately classifying new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0u0_dlPwX07H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_left =  7\n"
     ]
    }
   ],
   "source": [
    "def make_partition(data, feature, threshold):\n",
    "    \"\"\"\n",
    "    This function will split the data into 2 branches\n",
    "    args:\n",
    "    * data(type: DataFrame): the input data\n",
    "    * feature(type: string): the attribute(column name)\n",
    "    * threshold(type: float): the threshold for splitting the data\n",
    "    return:\n",
    "    * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold\n",
    "    * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    mask = data[feature] <= threshold\n",
    "    left = data[mask]\n",
    "    right = data[~mask]\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return left, right\n",
    "\n",
    "\n",
    "# [Note] You have to save the value of \"ans_left\" into the output file\n",
    "# Here, let's assume the best split is when we choose bmi as the feature and threshold as 21.0\n",
    "left, right = make_partition(input_data, 'bmi', 21.0)\n",
    "ans_left = left.shape[0]\n",
    "print(\"ans_left = \", ans_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJjyqmgXj2GX"
   },
   "source": [
    "Expected output:\n",
    "> ans_left = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJKThK7yX8XX"
   },
   "source": [
    "### Step 5: Build the Decision Tree\n",
    "Hang in there... we are almost done with this section!\n",
    "\n",
    "Now, you need to use the above functions to complete a build_tree function.\n",
    "\n",
    "> Method:\n",
    "1.  If current depth < max_depth and the remaining number of samples > min_samples_split: continue to classify those samples\n",
    "2.  Use function *find_best_split()* to find the best split combination\n",
    "3.  If the obtained information gain is **greater than 0**: can build a deeper decision tree (add depth)\n",
    "4. Use function *make_partition()* to split the data into two parts\n",
    "5. Save the features and corresponding thresholds (starting from the root) used by the decision tree into *ans_features[]* and *ans_thresholds[]* respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZC7qkOjAYAlQ"
   },
   "outputs": [],
   "source": [
    "def build_tree(data, max_depth, min_samples_split, depth):\n",
    "    \"\"\"\n",
    "    This function will build the decision tree\n",
    "    args:\n",
    "    * data(type: DataFrame): the data you want to apply to the decision tree\n",
    "    * max_depth: the maximum depth of a decision tree\n",
    "    * min_samples_split: the minimum number of instances required to do partition\n",
    "    * depth: the height of the current decision tree\n",
    "    return:\n",
    "    * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    # check the condition of current depth and the remaining number of samples\n",
    "    if (depth < max_depth) and (len(data) > min_samples_split) :\n",
    "        # call find_best_split() to find the best combination\n",
    "        ig, threshold, feature = find_best_split(data, 'basic')\n",
    "        #print(ig,threshold,feature)\n",
    "        # check the value of information gain is greater than 0 or not\n",
    "        if ig > 0 :\n",
    "            # update the depth\n",
    "            depth += 1\n",
    "            # call make_partition() to split the data into two parts\n",
    "            left, right = make_partition(data, feature, threshold)\n",
    "            \n",
    "            # If there is no data split to the left tree OR no data split to the right tree\n",
    "            if (left.shape[0] == 0) or (right.shape[0] == 0):# or (len(left['hospital_death'].unique()) == 1) or (len(right['hospital_death'].unique()) == 1):\n",
    "                # return the label of the majority\n",
    "                label = data['hospital_death'].mode()[0]\n",
    "                return label\n",
    "            else:\n",
    "                question = \"{} {} {}\".format(feature, \"<=\", threshold)\n",
    "                subtree = {question: []}\n",
    "                \n",
    "                # call function build_tree() to recursively build the left subtree and right subtree\n",
    "                left_subtree = build_tree(left, max_depth, min_samples_split, depth)\n",
    "                right_subtree = build_tree(right, max_depth, min_samples_split, depth)\n",
    "                if left_subtree == right_subtree:\n",
    "                    subtree = left_subtree\n",
    "                else:\n",
    "                    subtree[question].append(left_subtree)\n",
    "                    subtree[question].append(right_subtree)\n",
    "                    ans_features.append(feature)\n",
    "                    ans_thresholds.append(threshold)\n",
    "        else:\n",
    "            # return the label of the majority\n",
    "            label = data['hospital_death'].mode()[0]\n",
    "            return label\n",
    "    else:\n",
    "        # return the label of the majority\n",
    "        label = data['hospital_death'].mode()[0]\n",
    "        return label\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return subtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7URY3IMkULl"
   },
   "source": [
    "An example of the output from *build_tree()*\n",
    "```\n",
    "{'bmi <= 33.5': [1, {'age <= 68.5': [0, 1]}]}\n",
    "```\n",
    "Therefore,\n",
    "```\n",
    "ans_features = ['bmi', 'age']\n",
    "ans_thresholds = [33.5, 68.5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dAuaqjhuYQSi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glucose_apache <= 99.5': [{'height <= 184.15': [0, 1]}, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, let's build a decision tree using the input_data\n",
    "\n",
    "ans_features = []\n",
    "ans_thresholds = []\n",
    "\n",
    "decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)\n",
    "decisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cD6A_jADyTjw"
   },
   "source": [
    "Expected output:\n",
    "> decisionTree = {'glucose_apache <= 99.5': [{'height <= 184.15': [0, 1]}, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oTdQ3vVkYYEQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['height', 'glucose_apache']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Note] You have to save the features in the \"decisionTree\" structure into the output file\n",
    "ans_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZO17E9vkbi4"
   },
   "source": [
    "Expected output:\n",
    "> ans_features = ['height', 'glucose_apache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BUeZh1o5YYem"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[184.15, 99.5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Note] You have to save the corresponding thresholds for the features in the \"ans_features\" list into the output file\n",
    "ans_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUPTy5RWj-1D"
   },
   "source": [
    "Expected output:\n",
    "> ans_thresholds = [184.15, 99.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69TQQNVaYdmp"
   },
   "source": [
    "### Step 6: Save answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "B9DosXRQYbDg"
   },
   "outputs": [],
   "source": [
    "basic = []\n",
    "basic.append(ans_entropy)\n",
    "basic.append(ans_informationGain)\n",
    "basic.append([ans_ig, ans_value, ans_name])\n",
    "basic.append(ans_left)\n",
    "basic.append(ans_features + ans_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpMpPwySYlUu"
   },
   "source": [
    "## Section 2: Build a Decision Tree Model\n",
    "\n",
    "Congrats! You have completed all 5 crucial functions. Now, we will use the functions above to implement a simple decision tree. You will train the decision tree using a training set and make predictions using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1egGj-lYn6O"
   },
   "source": [
    "### Step 1: Split data into training set and validation set\n",
    "> Note: We have split the data into training set and validation. You **cannot** change the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GAHFMO4QYpZ1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 11)\n",
      "(30, 11)\n",
      "(10, 11)\n"
     ]
    }
   ],
   "source": [
    "num_train = 30\n",
    "num_validation = 10\n",
    "\n",
    "training_data = input_data.iloc[:num_train]\n",
    "validation_data = input_data.iloc[-num_validation:]\n",
    "\n",
    "y_train = training_data[['hospital_death']]\n",
    "x_train = training_data.drop(['hospital_death'], axis=1)\n",
    "\n",
    "y_validation = validation_data[['hospital_death']]\n",
    "x_validation = validation_data.drop(['hospital_death'], axis=1)\n",
    "y_validation = y_validation.values.flatten()\n",
    "\n",
    "print(input_data.shape)\n",
    "print(training_data.shape)\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQlhfOJ0YySZ"
   },
   "source": [
    "### Step 2 to 4 : Make predictions with a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5IHxhEjY1rN"
   },
   "source": [
    "Define the attributions of the decision tree\n",
    "> You **cannot** modify the values of these attributes in this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Vwt7BRJ1Y3hD"
   },
   "outputs": [],
   "source": [
    "max_depth = 2\n",
    "depth = 0\n",
    "min_samples_split = 2\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-ly7gvtY5VQ"
   },
   "source": [
    "We have finished the function 'classify_data()' below, however, you can modify this function if you prefer completing it on your own way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "V4LfxAnYY6UQ"
   },
   "outputs": [],
   "source": [
    "def classify_data(instance, tree):\n",
    "    \"\"\"\n",
    "    This function will predict/classify the input instance\n",
    "    args:\n",
    "    * instance: a instance(case) to be predicted\n",
    "    return:\n",
    "    * answer: the prediction result (the classification result)\n",
    "    \"\"\"\n",
    "    equation = list(tree.keys())[0]\n",
    "    if equation.split()[1] == '<=':\n",
    "        temp_feature = equation.split()[0]\n",
    "        temp_threshold = equation.split()[2]\n",
    "        if instance[temp_feature] > float(temp_threshold):\n",
    "            answer = tree[equation][1]\n",
    "        else:\n",
    "            answer = tree[equation][0]\n",
    "    else:\n",
    "        if instance[equation.split()[0]] in (equation.split()[2]):\n",
    "            answer = tree[equation][0]\n",
    "        else:\n",
    "            answer = tree[equation][1]\n",
    "\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        return classify_data(instance, answer)\n",
    "\n",
    "\n",
    "def make_prediction(tree, data):\n",
    "    \"\"\"\n",
    "    This function will use your pre-trained decision tree to predict the labels of all instances in data\n",
    "    args:\n",
    "    * tree: the decision tree\n",
    "    * data: the data to predict\n",
    "    return:\n",
    "    * y_prediction: the predictions\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    # [Note] You can call the function classify_data() to predict the label of each instance\n",
    "    y_prediction = []\n",
    "    for idx, i in data.iterrows():\n",
    "        y_prediction.append(classify_data(i, tree))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return y_prediction\n",
    "\n",
    "\n",
    "def calculate_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function will calculate the f1-score of the predictions\n",
    "    args:\n",
    "    * y_true: the ground truth\n",
    "    * y_pred: the predictions\n",
    "    return:\n",
    "    * score: the f1-score\n",
    "    \"\"\"\n",
    "    score = f1_score(y_true, y_pred)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_VEmtbmtZLQJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_f1score =  0.4444\n"
     ]
    }
   ],
   "source": [
    "decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)\n",
    "\n",
    "y_pred = make_prediction(decision_tree, x_validation)\n",
    "\n",
    "# [Note] You have to save the value of \"ans_f1score\" into your output file\n",
    "# Please round your answer to 4 decimal place\n",
    "ans_f1score = calculate_score(y_validation, y_pred)\n",
    "ans_f1score = round(ans_f1score, 4)\n",
    "print(\"ans_f1score = \", ans_f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUcJZRYZk4kX"
   },
   "source": [
    "Expected output:\n",
    "> ans_f1score =  0.4444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5t58_-BwpGnY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just for you to check your predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7NM7CvdpHzb"
   },
   "source": [
    "Expected output:\n",
    "> y_pred = [1, 1, 0, 1, 0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COjs0B5jZQ8y"
   },
   "source": [
    "### Step 5: Save answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Hijx-U2yZUAk"
   },
   "outputs": [],
   "source": [
    "basic.append(ans_f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9lr2gbVZUwc"
   },
   "source": [
    "## Write to Output File\n",
    "Save all of your answers into a csv file named **lab2_basic.csv**\n",
    "> Note: Please do not touch the code in this step, we have made sure this outputs the correct file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "a5_ifgVZZZKZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ans</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.2146, 99.5, glucose_apache]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[height, glucose_apache, 184.15, 99.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Ans\n",
       "Id                                        \n",
       "0                                   0.9928\n",
       "1                                   0.0385\n",
       "2           [0.2146, 99.5, glucose_apache]\n",
       "3                                        7\n",
       "4   [height, glucose_apache, 184.15, 99.5]\n",
       "5                                   0.4444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_path = 'lab2_basic.csv'\n",
    "\n",
    "basic_df = pd.DataFrame({'Id': range(len(basic)), 'Ans': basic})\n",
    "basic_df.set_index('Id', inplace=True)\n",
    "basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OTK0JT1965qS"
   },
   "outputs": [],
   "source": [
    "basic_df.to_csv(basic_path, header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chm8Ro6zZsWp"
   },
   "source": [
    "# **Advanced Part** (65%)\n",
    "\n",
    "In the advanced section of this lab, you will enhance your prediction capabilities by implementing a more powerful and complex machine learning model—Random Forests. Random Forests are an ensemble learning method that builds multiple decision trees and combines their outputs to improve prediction accuracy and model robustness.\n",
    "> * Step 1: Load training and testing data\n",
    "> * Step 2: Split training data into training and validation set\n",
    "> * Step 3: Build a Random Forest\n",
    "> * Step 4: Make predictions with the random forest\n",
    "> * Step 5: Write the Output File\n",
    "\n",
    "> ❗ **Important** ❗ You are allowed to create new functions to fine tune your random forest, but please make sure to **complete the functions provided**.\n",
    "\n",
    "\n",
    "\n",
    "We have attached some references if you need help:\n",
    "> https://medium.com/chung-yi/ml%E5%85%A5%E9%96%80-%E5%8D%81%E4%B8%83-%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-6afc24871857\n",
    "\n",
    "> https://www.geeksforgeeks.org/random-forest-algorithm-in-machine-learning/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kBs4D02Z0Ub"
   },
   "source": [
    "### Step 1: Load training and testing data\n",
    "First, load **lab2_advanced_training.csv**. You will use this to **train** the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vLTMFK14Z4z5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>pre_icu_los_days</th>\n",
       "      <th>arf_apache</th>\n",
       "      <th>bun_apache</th>\n",
       "      <th>creatinine_apache</th>\n",
       "      <th>gcs_eyes_apache</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_apache</th>\n",
       "      <th>ventilated_apache</th>\n",
       "      <th>wbc_apache</th>\n",
       "      <th>apache_4a_hospital_death_prob</th>\n",
       "      <th>apache_4a_icu_death_prob</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.0</td>\n",
       "      <td>25.616497</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0</td>\n",
       "      <td>72.3</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.0</td>\n",
       "      <td>23.494409</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>29.145882</td>\n",
       "      <td>0</td>\n",
       "      <td>182.9</td>\n",
       "      <td>97.5</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0</td>\n",
       "      <td>41.183318</td>\n",
       "      <td>1</td>\n",
       "      <td>170.2</td>\n",
       "      <td>119.3</td>\n",
       "      <td>1.945139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.0</td>\n",
       "      <td>22.914211</td>\n",
       "      <td>0</td>\n",
       "      <td>170.1</td>\n",
       "      <td>66.3</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>55.0</td>\n",
       "      <td>33.201250</td>\n",
       "      <td>0</td>\n",
       "      <td>165.1</td>\n",
       "      <td>90.5</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>87.0</td>\n",
       "      <td>29.756001</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>80.0</td>\n",
       "      <td>17.630854</td>\n",
       "      <td>1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.80</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>74.0</td>\n",
       "      <td>19.199423</td>\n",
       "      <td>0</td>\n",
       "      <td>175.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>77.0</td>\n",
       "      <td>29.412958</td>\n",
       "      <td>1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8500 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age        bmi  gender  height  weight  pre_icu_los_days  arf_apache  \\\n",
       "0     79.0  25.616497       1   168.0    72.3          0.305556         0.0   \n",
       "1     43.0  23.494409       0   171.0    68.7          0.011806         0.0   \n",
       "2     62.0  29.145882       0   182.9    97.5          0.006250         0.0   \n",
       "3     72.0  41.183318       1   170.2   119.3          1.945139         0.0   \n",
       "4     87.0  22.914211       0   170.1    66.3          0.085417         0.0   \n",
       "...    ...        ...     ...     ...     ...               ...         ...   \n",
       "8495  55.0  33.201250       0   165.1    90.5          0.052083         0.0   \n",
       "8496  87.0  29.756001       1   142.0    60.0          0.014583         0.0   \n",
       "8497  80.0  17.630854       1   165.0    48.0          0.102778         0.0   \n",
       "8498  74.0  19.199423       0   175.3    59.0          0.460417         0.0   \n",
       "8499  77.0  29.412958       1   157.0    72.5          0.538889         0.0   \n",
       "\n",
       "      bun_apache  creatinine_apache  gcs_eyes_apache  ...  temp_apache  \\\n",
       "0           20.0               0.92              4.0  ...         36.3   \n",
       "1            9.0               0.70              1.0  ...         39.5   \n",
       "2           54.0               3.59              1.0  ...         35.0   \n",
       "3           53.0               2.25              4.0  ...         37.1   \n",
       "4           33.0               1.60              4.0  ...         36.1   \n",
       "...          ...                ...              ...  ...          ...   \n",
       "8495        15.0               1.09              4.0  ...         37.7   \n",
       "8496        17.0               0.80              4.0  ...         35.7   \n",
       "8497        30.0               0.90              3.0  ...         35.6   \n",
       "8498        39.0               2.19              1.0  ...         33.7   \n",
       "8499        22.0               0.94              4.0  ...         36.3   \n",
       "\n",
       "      ventilated_apache  wbc_apache  apache_4a_hospital_death_prob  \\\n",
       "0                   1.0        7.20                           0.28   \n",
       "1                   1.0       21.20                           0.53   \n",
       "2                   1.0       19.20                           0.62   \n",
       "3                   0.0       10.40                           0.11   \n",
       "4                   1.0       16.50                           0.16   \n",
       "...                 ...         ...                            ...   \n",
       "8495                1.0        7.60                           0.06   \n",
       "8496                0.0       11.70                           0.05   \n",
       "8497                1.0       45.80                           0.25   \n",
       "8498                1.0        3.20                           0.79   \n",
       "8499                0.0        1.93                           0.17   \n",
       "\n",
       "      apache_4a_icu_death_prob  aids  cirrhosis  diabetes_mellitus  leukemia  \\\n",
       "0                         0.07   0.0        0.0                0.0       0.0   \n",
       "1                         0.48   0.0        0.0                0.0       0.0   \n",
       "2                         0.45   0.0        0.0                0.0       0.0   \n",
       "3                         0.02   0.0        0.0                1.0       0.0   \n",
       "4                         0.08   0.0        0.0                0.0       0.0   \n",
       "...                        ...   ...        ...                ...       ...   \n",
       "8495                      0.04   0.0        0.0                0.0       0.0   \n",
       "8496                      0.02   0.0        0.0                0.0       0.0   \n",
       "8497                      0.12   0.0        0.0                0.0       0.0   \n",
       "8498                      0.72   0.0        0.0                0.0       0.0   \n",
       "8499                      0.09   0.0        0.0                1.0       0.0   \n",
       "\n",
       "      hospital_death  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  0  \n",
       "...              ...  \n",
       "8495               0  \n",
       "8496               0  \n",
       "8497               1  \n",
       "8498               1  \n",
       "8499               0  \n",
       "\n",
       "[8500 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_training_data = pd.read_csv('lab2_advanced_training.csv')\n",
    "advanced_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjPSZoAuZ4Ry"
   },
   "source": [
    "Next, load **lab2_advanced_testing.csv**. You will make predictions on this testing data using the pre-trained random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6k-HFk7tZ_eN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>pre_icu_los_days</th>\n",
       "      <th>arf_apache</th>\n",
       "      <th>bun_apache</th>\n",
       "      <th>creatinine_apache</th>\n",
       "      <th>gcs_eyes_apache</th>\n",
       "      <th>...</th>\n",
       "      <th>sodium_apache</th>\n",
       "      <th>temp_apache</th>\n",
       "      <th>ventilated_apache</th>\n",
       "      <th>wbc_apache</th>\n",
       "      <th>apache_4a_hospital_death_prob</th>\n",
       "      <th>apache_4a_icu_death_prob</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>leukemia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "      <td>38.733847</td>\n",
       "      <td>1</td>\n",
       "      <td>158.23</td>\n",
       "      <td>96.82</td>\n",
       "      <td>0.232639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>22.692476</td>\n",
       "      <td>0</td>\n",
       "      <td>173.67</td>\n",
       "      <td>69.40</td>\n",
       "      <td>0.121528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>33.702285</td>\n",
       "      <td>0</td>\n",
       "      <td>177.47</td>\n",
       "      <td>105.70</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>33.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>20.274075</td>\n",
       "      <td>0</td>\n",
       "      <td>171.74</td>\n",
       "      <td>61.10</td>\n",
       "      <td>0.664583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>36.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>29.027749</td>\n",
       "      <td>1</td>\n",
       "      <td>175.75</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>149</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>61</td>\n",
       "      <td>22.840598</td>\n",
       "      <td>0</td>\n",
       "      <td>174.96</td>\n",
       "      <td>71.20</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>74</td>\n",
       "      <td>28.843833</td>\n",
       "      <td>1</td>\n",
       "      <td>169.31</td>\n",
       "      <td>82.90</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>36.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>68</td>\n",
       "      <td>22.744572</td>\n",
       "      <td>1</td>\n",
       "      <td>170.02</td>\n",
       "      <td>67.05</td>\n",
       "      <td>2.172917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>35.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>55</td>\n",
       "      <td>25.356784</td>\n",
       "      <td>0</td>\n",
       "      <td>169.90</td>\n",
       "      <td>73.90</td>\n",
       "      <td>4.186111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>35.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>62</td>\n",
       "      <td>16.720580</td>\n",
       "      <td>1</td>\n",
       "      <td>165.40</td>\n",
       "      <td>46.00</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age        bmi  gender  height  weight  pre_icu_los_days  arf_apache  \\\n",
       "0     82  38.733847       1  158.23   96.82          0.232639         0.0   \n",
       "1     65  22.692476       0  173.67   69.40          0.121528         0.0   \n",
       "2     72  33.702285       0  177.47  105.70          0.143750         0.0   \n",
       "3     81  20.274075       0  171.74   61.10          0.664583         0.0   \n",
       "4     41  29.027749       1  175.75   90.00          0.004167         0.0   \n",
       "..   ...        ...     ...     ...     ...               ...         ...   \n",
       "895   61  22.840598       0  174.96   71.20          0.009722         0.0   \n",
       "896   74  28.843833       1  169.31   82.90          0.389583         0.0   \n",
       "897   68  22.744572       1  170.02   67.05          2.172917         0.0   \n",
       "898   55  25.356784       0  169.90   73.90          4.186111         0.0   \n",
       "899   62  16.720580       1  165.40   46.00          0.157639         0.0   \n",
       "\n",
       "     bun_apache  creatinine_apache  gcs_eyes_apache  ...  sodium_apache  \\\n",
       "0            50               3.32              1.0  ...            135   \n",
       "1            33               1.40              1.0  ...            133   \n",
       "2            17               1.71              1.0  ...            143   \n",
       "3            35               2.09              3.0  ...            136   \n",
       "4             3               0.41              1.0  ...            149   \n",
       "..          ...                ...              ...  ...            ...   \n",
       "895          22               0.90              4.0  ...            134   \n",
       "896          12               0.74              3.0  ...            144   \n",
       "897          36               1.87              3.0  ...            137   \n",
       "898          12               1.38              4.0  ...            139   \n",
       "899          11               2.80              4.0  ...            135   \n",
       "\n",
       "     temp_apache  ventilated_apache  wbc_apache  \\\n",
       "0           33.0                1.0        14.8   \n",
       "1           32.1                1.0        12.5   \n",
       "2           33.9                1.0        17.8   \n",
       "3           36.4                1.0         9.0   \n",
       "4           32.3                1.0        24.0   \n",
       "..           ...                ...         ...   \n",
       "895         36.5                0.0         5.2   \n",
       "896         36.4                1.0         9.9   \n",
       "897         35.8                1.0        29.7   \n",
       "898         35.9                1.0        15.3   \n",
       "899         36.2                1.0         5.8   \n",
       "\n",
       "     apache_4a_hospital_death_prob  apache_4a_icu_death_prob  aids  cirrhosis  \\\n",
       "0                             0.84                      0.71   0.0        0.0   \n",
       "1                             0.70                      0.54   0.0        0.0   \n",
       "2                             0.49                      0.29   0.0        0.0   \n",
       "3                             0.40                      0.31   0.0        0.0   \n",
       "4                             0.71                      0.64   0.0        0.0   \n",
       "..                             ...                       ...   ...        ...   \n",
       "895                           0.04                      0.03   0.0        0.0   \n",
       "896                           0.02                      0.00   0.0        0.0   \n",
       "897                           0.16                      0.11   0.0        0.0   \n",
       "898                           0.01                     -0.02   0.0        0.0   \n",
       "899                           0.08                      0.04   0.0        0.0   \n",
       "\n",
       "     diabetes_mellitus  leukemia  \n",
       "0                  0.0       0.0  \n",
       "1                  1.0       0.0  \n",
       "2                  0.0       0.0  \n",
       "3                  0.0       0.0  \n",
       "4                  0.0       0.0  \n",
       "..                 ...       ...  \n",
       "895                0.0       0.0  \n",
       "896                0.0       0.0  \n",
       "897                1.0       0.0  \n",
       "898                0.0       0.0  \n",
       "899                0.0       0.0  \n",
       "\n",
       "[900 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_testing_data = pd.read_csv('lab2_advanced_testing.csv')\n",
    "advanced_testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMQdTAvOaIh6"
   },
   "source": [
    "### Step 2: Split training data into training and validation set (Optional)\n",
    "> You can split the training data into training and validation set, this is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "iMan7jJ-aKX9"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "#advanced_training_data = advanced_training_data.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "split = int(8500 * 0.8)\n",
    "training_data = advanced_training_data[:split+1]\n",
    "validation_data = advanced_training_data[split+1:]\n",
    "\n",
    "y_validation = validation_data[['hospital_death']]\n",
    "x_validation = validation_data.drop(['hospital_death'], axis=1)\n",
    "y_validation = y_validation.values.flatten()\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY8HvRY4af3u"
   },
   "source": [
    "### Step 3: Build a Random Forest\n",
    "\n",
    "Define the attributions of the random forest\n",
    "> * You **can** modify the values of these attributes in advanced part\n",
    "> * Each tree can have different attribute values\n",
    "> * Must use function *build_tree()* to build a random forest model\n",
    "> * Must print out the *selected_datas* and *selected_features*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "xK0iM7goa2pj"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# Define the attributes\n",
    "max_depth = 2\n",
    "depth = 0\n",
    "min_samples_split = 2\n",
    "\n",
    "# total number of trees in a random forest\n",
    "n_trees = 5\n",
    "\n",
    "# number of features to train a decision tree\n",
    "n_features = int(round(np.log2(training_data.shape[1]-1)))\n",
    "#n_features = int(round(sqrt(training_data.shape[1]-1)))\n",
    "\n",
    "# the ratio to select the number of instances\n",
    "sample_size = 0.8\n",
    "n_samples = int(training_data.shape[0] * sample_size)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "i1I7wbpWa_N1"
   },
   "outputs": [],
   "source": [
    "def build_forest(data, n_trees, n_features, n_samples):\n",
    "    \"\"\"\n",
    "    This function will build a random forest.\n",
    "    args:\n",
    "    * data: all data that can be used to train a random forest\n",
    "    * n_trees: total number of tree\n",
    "    * n_features: number of features\n",
    "    * n_samples: number of instances\n",
    "    return:\n",
    "    * forest: a random forest with 'n_trees' of decision tree\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    data_len = n_samples\n",
    "    feature_list = list(data.columns)\n",
    "    feature_list.remove('hospital_death')\n",
    "    forest = []\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Create 'n_trees' number of trees and store each into the 'forest' list\n",
    "    for i in range(n_trees):\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Select 'n_samples' number of samples and 'n_features' number of features\n",
    "        # (you can select randomly or use any other techniques)\n",
    "        selected_datas = data.sample(n = n_samples, replace = True)\n",
    "        selected_features = np.random.choice(feature_list, n_features, replace = False).tolist()\n",
    "        selected_features.append('hospital_death')\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        print(f\"selected_datas = {selected_datas}\")\n",
    "        print(f\"selected_features = {selected_features}\")\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Store the rows in 'selected_datas' from 'data' into a new DataFrame\n",
    "        #tree_data = pd.DataFrame()\n",
    "        #rows = []\n",
    "        #for i, r in data.iterrows():\n",
    "        #   rows.append(r)\n",
    "        #tree_data = pd.concat([tree_data, pd.DataFrame(rows)], ignore_index = True)\n",
    "\n",
    "        # Filter the DataFrame for specific 'selected_features' (columns)\n",
    "        tree_data = selected_datas[selected_features]\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Then use the new data and 'build_tree' function to build a tree\n",
    "        tree = build_tree(tree_data, max_depth, min_samples_split, depth)\n",
    "        print(tree)\n",
    "\n",
    "        # Save your tree\n",
    "        forest.append(tree)\n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "WvV8U7C2bIqO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_datas =        age        bmi  gender  height  weight  pre_icu_los_days  arf_apache  \\\n",
      "3359  74.0  26.152302       0   172.7    78.0          0.048611         0.0   \n",
      "2717  51.0  24.858470       1   166.0    68.5          0.078472         0.0   \n",
      "4962  52.0  27.493071       1   157.5    68.2          0.271528         1.0   \n",
      "3503  61.0  33.710938       1   160.0    86.3          1.301389         0.0   \n",
      "420   69.0  28.632002       1   152.4    66.5          0.146528         0.0   \n",
      "...    ...        ...     ...     ...     ...               ...         ...   \n",
      "3154  52.0  28.636428       0   175.3    88.0          0.004861         0.0   \n",
      "6683  44.0  33.036950       0   167.6    92.8          0.018750         0.0   \n",
      "410   72.0  28.343341       0   175.2    87.0          5.326389         0.0   \n",
      "1584  73.0  14.844926       1   165.0    40.0          0.061806         0.0   \n",
      "1843  79.0  18.123113       1   165.1    49.4          0.000694         0.0   \n",
      "\n",
      "      bun_apache  creatinine_apache  gcs_eyes_apache  ...  temp_apache  \\\n",
      "3359        17.0               1.30              4.0  ...         36.8   \n",
      "2717         8.0               0.48              4.0  ...         36.1   \n",
      "4962        41.0               7.38              2.0  ...         35.8   \n",
      "3503        37.0               3.00              2.0  ...         33.7   \n",
      "420         11.0               0.86              4.0  ...         36.4   \n",
      "...          ...                ...              ...  ...          ...   \n",
      "3154        12.0               0.56              4.0  ...         35.9   \n",
      "6683        15.0               1.33              4.0  ...         36.7   \n",
      "410         18.0               1.37              2.0  ...         36.7   \n",
      "1584         4.0               0.35              4.0  ...         36.5   \n",
      "1843        17.0               0.80              4.0  ...         34.9   \n",
      "\n",
      "      ventilated_apache  wbc_apache  apache_4a_hospital_death_prob  \\\n",
      "3359                0.0        14.1                           0.04   \n",
      "2717                0.0        10.2                           0.02   \n",
      "4962                0.0        10.6                           0.11   \n",
      "3503                1.0        23.2                           0.47   \n",
      "420                 1.0         9.3                           0.04   \n",
      "...                 ...         ...                            ...   \n",
      "3154                1.0         8.4                           0.20   \n",
      "6683                1.0        12.2                           0.01   \n",
      "410                 1.0        18.5                           0.26   \n",
      "1584                1.0        14.1                           0.14   \n",
      "1843                1.0        14.1                           0.06   \n",
      "\n",
      "      apache_4a_icu_death_prob  aids  cirrhosis  diabetes_mellitus  leukemia  \\\n",
      "3359                      0.01   0.0        0.0                1.0       0.0   \n",
      "2717                      0.01   0.0        0.0                0.0       0.0   \n",
      "4962                      0.09   0.0        0.0                1.0       0.0   \n",
      "3503                      0.33   0.0        0.0                0.0       0.0   \n",
      "420                       0.02   0.0        0.0                0.0       0.0   \n",
      "...                        ...   ...        ...                ...       ...   \n",
      "3154                      0.13   0.0        0.0                0.0       0.0   \n",
      "6683                      0.00   0.0        0.0                0.0       0.0   \n",
      "410                       0.12   0.0        0.0                0.0       0.0   \n",
      "1584                      0.08   0.0        0.0                0.0       0.0   \n",
      "1843                      0.03   0.0        0.0                0.0       0.0   \n",
      "\n",
      "      hospital_death  \n",
      "3359               0  \n",
      "2717               0  \n",
      "4962               0  \n",
      "3503               0  \n",
      "420                0  \n",
      "...              ...  \n",
      "3154               0  \n",
      "6683               0  \n",
      "410                1  \n",
      "1584               0  \n",
      "1843               0  \n",
      "\n",
      "[5440 rows x 30 columns]\n",
      "selected_features = ['gcs_verbal_apache', 'arf_apache', 'apache_4a_hospital_death_prob', 'gcs_eyes_apache', 'map_apache', 'hospital_death']\n",
      "{'apache_4a_hospital_death_prob <= 0.195': [0, 1]}\n",
      "selected_datas =        age        bmi  gender  height  weight  pre_icu_los_days  arf_apache  \\\n",
      "1361  81.0  23.961783       0   177.8   75.75          0.339583         0.0   \n",
      "1091  81.0  32.679232       1   152.4   75.90          0.898611         0.0   \n",
      "2514  46.0  40.228541       0   173.0  120.40          0.162500         0.0   \n",
      "5050  52.0  26.788143       0   170.2   77.60          0.452083         0.0   \n",
      "3682  41.0  27.147983       1   165.1   74.00         10.398611         0.0   \n",
      "...    ...        ...     ...     ...     ...               ...         ...   \n",
      "1536  35.0  31.112519       0   175.2   95.50          0.159722         0.0   \n",
      "5773  47.0  37.736171       1   167.6  106.00          0.136111         0.0   \n",
      "6490  71.0  40.477384       0   167.6  113.70          0.079861         0.0   \n",
      "2708  69.0  41.919825       0   175.3  128.82          0.325694         0.0   \n",
      "4154  41.0  36.555002       0   188.0  129.20          0.100694         0.0   \n",
      "\n",
      "      bun_apache  creatinine_apache  gcs_eyes_apache  ...  temp_apache  \\\n",
      "1361        31.0               1.12              4.0  ...         35.9   \n",
      "1091        34.0               0.70              4.0  ...         35.9   \n",
      "2514        11.0               0.92              3.0  ...         36.7   \n",
      "5050        12.0               1.11              4.0  ...         36.4   \n",
      "3682         7.0               0.56              4.0  ...         36.5   \n",
      "...          ...                ...              ...  ...          ...   \n",
      "1536         8.0               0.90              4.0  ...         36.4   \n",
      "5773         7.0               0.62              1.0  ...         36.1   \n",
      "6490        59.0               2.07              4.0  ...         36.9   \n",
      "2708        12.0               0.61              4.0  ...         35.6   \n",
      "4154        18.0               1.43              4.0  ...         36.4   \n",
      "\n",
      "      ventilated_apache  wbc_apache  apache_4a_hospital_death_prob  \\\n",
      "1361                0.0       10.60                           0.04   \n",
      "1091                1.0        5.67                           0.27   \n",
      "2514                0.0       17.80                           0.02   \n",
      "5050                0.0       12.20                           0.01   \n",
      "3682                0.0       20.90                           0.02   \n",
      "...                 ...         ...                            ...   \n",
      "1536                0.0        4.40                           0.04   \n",
      "5773                1.0       10.70                           0.41   \n",
      "6490                1.0       29.70                           0.12   \n",
      "2708                0.0       13.46                           0.02   \n",
      "4154                0.0       10.30                           0.02   \n",
      "\n",
      "      apache_4a_icu_death_prob  aids  cirrhosis  diabetes_mellitus  leukemia  \\\n",
      "1361                      0.01   0.0        0.0                0.0       0.0   \n",
      "1091                      0.13   0.0        0.0                0.0       0.0   \n",
      "2514                      0.01   0.0        0.0                0.0       0.0   \n",
      "5050                      0.00   0.0        0.0                0.0       0.0   \n",
      "3682                      0.01   0.0        0.0                0.0       0.0   \n",
      "...                        ...   ...        ...                ...       ...   \n",
      "1536                      0.02   0.0        0.0                0.0       0.0   \n",
      "5773                      0.39   0.0        0.0                0.0       0.0   \n",
      "6490                      0.07   0.0        0.0                1.0       0.0   \n",
      "2708                      0.01   0.0        0.0                1.0       0.0   \n",
      "4154                      0.01   0.0        0.0                0.0       0.0   \n",
      "\n",
      "      hospital_death  \n",
      "1361               0  \n",
      "1091               0  \n",
      "2514               0  \n",
      "5050               0  \n",
      "3682               0  \n",
      "...              ...  \n",
      "1536               0  \n",
      "5773               0  \n",
      "6490               0  \n",
      "2708               0  \n",
      "4154               0  \n",
      "\n",
      "[5440 rows x 30 columns]\n",
      "selected_features = ['resprate_apache', 'wbc_apache', 'diabetes_mellitus', 'pre_icu_los_days', 'intubated_apache', 'hospital_death']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intubated_apache <= 0.5': [{'wbc_apache <= 19.91': [0, 1]}, 1]}\n",
      "selected_datas =        age        bmi  gender  height  weight  pre_icu_los_days  arf_apache  \\\n",
      "1635  67.0  38.281250       1   160.0    98.0          2.767361         0.0   \n",
      "6349  68.0  31.875000       1   160.0    81.6          0.005556         0.0   \n",
      "4326  78.0  29.648980       0   175.0    90.8          0.072917         0.0   \n",
      "3181  36.0  26.391071       0   175.3    81.1          0.073611         0.0   \n",
      "4835  60.0  18.730489       1   155.0    45.0          0.120139         0.0   \n",
      "...    ...        ...     ...     ...     ...               ...         ...   \n",
      "4891  59.0  26.048168       1   154.9    62.5          0.000694         0.0   \n",
      "6110  51.0  67.814990       0   165.1   186.0          1.046528         0.0   \n",
      "2740  52.0  35.098955       0   180.3   114.1          0.110417         0.0   \n",
      "6671  29.0  36.589292       0   182.9   122.4          0.114583         0.0   \n",
      "4877  75.0  17.566702       1   152.4    40.8          0.619444         0.0   \n",
      "\n",
      "      bun_apache  creatinine_apache  gcs_eyes_apache  ...  temp_apache  \\\n",
      "1635        18.0               0.90              3.0  ...         35.3   \n",
      "6349         9.0               0.81              4.0  ...         36.2   \n",
      "4326        36.0               2.27              1.0  ...         33.4   \n",
      "3181        12.0               1.10              1.0  ...         36.7   \n",
      "4835        24.0               0.46              3.0  ...         36.3   \n",
      "...          ...                ...              ...  ...          ...   \n",
      "4891        14.0               0.71              4.0  ...         36.4   \n",
      "6110        31.0               1.20              4.0  ...         37.0   \n",
      "2740        11.0               0.43              4.0  ...         37.1   \n",
      "6671        19.0               1.68              4.0  ...         36.1   \n",
      "4877        24.0               0.66              1.0  ...         36.4   \n",
      "\n",
      "      ventilated_apache  wbc_apache  apache_4a_hospital_death_prob  \\\n",
      "1635                1.0        2.51                           0.24   \n",
      "6349                0.0       15.20                           0.01   \n",
      "4326                1.0       22.27                           0.83   \n",
      "3181                1.0       26.40                           0.57   \n",
      "4835                1.0       10.80                           0.20   \n",
      "...                 ...         ...                            ...   \n",
      "4891                0.0       12.30                           0.01   \n",
      "6110                1.0       27.90                           0.07   \n",
      "2740                0.0        7.20                           0.03   \n",
      "6671                0.0       10.60                           0.02   \n",
      "4877                1.0       13.00                           0.42   \n",
      "\n",
      "      apache_4a_icu_death_prob  aids  cirrhosis  diabetes_mellitus  leukemia  \\\n",
      "1635                      0.12   0.0        0.0                0.0       0.0   \n",
      "6349                      0.01   0.0        0.0                0.0       0.0   \n",
      "4326                      0.72   0.0        0.0                0.0       0.0   \n",
      "3181                      0.50   0.0        0.0                0.0       0.0   \n",
      "4835                      0.15   0.0        0.0                0.0       0.0   \n",
      "...                        ...   ...        ...                ...       ...   \n",
      "4891                      0.00   0.0        0.0                0.0       0.0   \n",
      "6110                      0.04   0.0        0.0                1.0       0.0   \n",
      "2740                      0.01   0.0        0.0                1.0       0.0   \n",
      "6671                      0.01   0.0        0.0                1.0       0.0   \n",
      "4877                      0.23   0.0        0.0                0.0       0.0   \n",
      "\n",
      "      hospital_death  \n",
      "1635               1  \n",
      "6349               0  \n",
      "4326               1  \n",
      "3181               0  \n",
      "4835               1  \n",
      "...              ...  \n",
      "4891               0  \n",
      "6110               1  \n",
      "2740               1  \n",
      "6671               0  \n",
      "4877               0  \n",
      "\n",
      "[5440 rows x 30 columns]\n",
      "selected_features = ['cirrhosis', 'hematocrit_apache', 'map_apache', 'temp_apache', 'apache_4a_hospital_death_prob', 'hospital_death']\n",
      "{'apache_4a_hospital_death_prob <= 0.165': [0, 1]}\n",
      "selected_datas =        age        bmi  gender  height  weight  pre_icu_los_days  arf_apache  \\\n",
      "2553  66.0  25.719814       1  162.60   68.00          0.014583         0.0   \n",
      "5407  79.0  22.583465       0  147.30   49.00          0.162500         0.0   \n",
      "3759  75.0  26.109994       0  177.00   81.80          0.141667         0.0   \n",
      "542   22.0  21.826285       0  187.96   77.11          0.015972         0.0   \n",
      "5978  66.0  22.167199       1  158.80   55.90          0.309722         0.0   \n",
      "...    ...        ...     ...     ...     ...               ...         ...   \n",
      "5770  72.0  28.050683       0  175.30   86.20          0.000000         0.0   \n",
      "2979  27.0  24.090347       0  173.00   72.10          1.847917         0.0   \n",
      "3503  61.0  33.710938       1  160.00   86.30          1.301389         0.0   \n",
      "3442  80.0  22.876601       0  175.30   70.30          0.000694         0.0   \n",
      "5152  66.0  29.515045       1  175.30   90.70          0.121528         0.0   \n",
      "\n",
      "      bun_apache  creatinine_apache  gcs_eyes_apache  ...  temp_apache  \\\n",
      "2553        42.0               2.05              1.0  ...        32.10   \n",
      "5407        44.0               1.26              2.0  ...        36.40   \n",
      "3759        84.0               2.74              2.0  ...        37.40   \n",
      "542          9.0               0.49              4.0  ...        36.80   \n",
      "5978        15.0               0.58              4.0  ...        35.80   \n",
      "...          ...                ...              ...  ...          ...   \n",
      "5770        58.0               2.03              4.0  ...        35.90   \n",
      "2979        10.0               0.77              1.0  ...        36.50   \n",
      "3503        37.0               3.00              2.0  ...        33.70   \n",
      "3442        15.0               0.70              1.0  ...        36.61   \n",
      "5152        15.0               1.04              4.0  ...        36.80   \n",
      "\n",
      "      ventilated_apache  wbc_apache  apache_4a_hospital_death_prob  \\\n",
      "2553                1.0        4.60                           0.93   \n",
      "5407                1.0        7.00                           0.26   \n",
      "3759                1.0        0.90                           0.82   \n",
      "542                 0.0        7.39                           0.02   \n",
      "5978                1.0       12.49                           0.02   \n",
      "...                 ...         ...                            ...   \n",
      "5770                1.0       10.00                          -1.00   \n",
      "2979                1.0       14.40                           0.05   \n",
      "3503                1.0       23.20                           0.47   \n",
      "3442                1.0       45.80                           0.57   \n",
      "5152                0.0        6.10                           0.04   \n",
      "\n",
      "      apache_4a_icu_death_prob  aids  cirrhosis  diabetes_mellitus  leukemia  \\\n",
      "2553                      0.90   0.0        0.0                1.0       1.0   \n",
      "5407                      0.14   0.0        0.0                1.0       0.0   \n",
      "3759                      0.74   0.0        0.0                1.0       0.0   \n",
      "542                       0.01   0.0        0.0                0.0       0.0   \n",
      "5978                      0.02   0.0        0.0                1.0       0.0   \n",
      "...                        ...   ...        ...                ...       ...   \n",
      "5770                     -1.00   0.0        0.0                1.0       0.0   \n",
      "2979                      0.05   0.0        0.0                0.0       0.0   \n",
      "3503                      0.33   0.0        0.0                0.0       0.0   \n",
      "3442                      0.44   0.0        0.0                0.0       0.0   \n",
      "5152                      0.02   0.0        0.0                0.0       0.0   \n",
      "\n",
      "      hospital_death  \n",
      "2553               1  \n",
      "5407               1  \n",
      "3759               1  \n",
      "542                0  \n",
      "5978               0  \n",
      "...              ...  \n",
      "5770               1  \n",
      "2979               0  \n",
      "3503               0  \n",
      "3442               1  \n",
      "5152               0  \n",
      "\n",
      "[5440 rows x 30 columns]\n",
      "selected_features = ['age', 'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob', 'creatinine_apache', 'aids', 'hospital_death']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apache_4a_icu_death_prob <= 0.07500000000000001': [0, 1]}\n",
      "selected_datas =        age        bmi  gender  height  weight  pre_icu_los_days  arf_apache  \\\n",
      "5395  83.0  33.820154       1   167.6    95.0          0.300694         0.0   \n",
      "1131  81.0  16.786480       1   163.0    44.6          0.006250         0.0   \n",
      "1938  68.0  26.485715       0   180.3    86.1          1.894444         0.0   \n",
      "6262  43.0  23.789635       0   173.0    71.2          2.081250         0.0   \n",
      "2729  78.0  28.626436       0   178.0    90.7          0.024306         0.0   \n",
      "...    ...        ...     ...     ...     ...               ...         ...   \n",
      "2140  57.0  24.537037       0   180.0    79.5          2.000694         0.0   \n",
      "6283  56.0  27.335640       1   170.0    79.0          0.260417         0.0   \n",
      "2170  59.0  23.163465       0   180.3    75.3          0.272917         0.0   \n",
      "3976  70.0  22.721216       1   185.4    78.1          0.140972         0.0   \n",
      "1243  83.0  33.246642       0   162.6    87.9          0.000000         0.0   \n",
      "\n",
      "      bun_apache  creatinine_apache  gcs_eyes_apache  ...  temp_apache  \\\n",
      "5395        11.0               0.77              2.0  ...         36.2   \n",
      "1131        17.0               1.49              4.0  ...         36.1   \n",
      "1938        28.0               0.90              3.0  ...         36.7   \n",
      "6262         9.0               0.66              4.0  ...         37.8   \n",
      "2729        20.0               0.80              4.0  ...         36.4   \n",
      "...          ...                ...              ...  ...          ...   \n",
      "2140        87.0               2.89              4.0  ...         37.6   \n",
      "6283        10.0               0.91              4.0  ...         36.7   \n",
      "2170        38.0               1.25              4.0  ...         35.6   \n",
      "3976        28.1               1.40              1.0  ...         35.2   \n",
      "1243        42.0               1.70              1.0  ...         32.3   \n",
      "\n",
      "      ventilated_apache  wbc_apache  apache_4a_hospital_death_prob  \\\n",
      "5395                0.0         8.9                           0.09   \n",
      "1131                0.0        13.5                           0.31   \n",
      "1938                1.0        14.2                           0.29   \n",
      "6262                0.0         7.8                           0.01   \n",
      "2729                0.0         9.8                           0.07   \n",
      "...                 ...         ...                            ...   \n",
      "2140                1.0        18.8                           0.42   \n",
      "6283                0.0         4.1                           0.04   \n",
      "2170                0.0        20.3                           0.17   \n",
      "3976                1.0        43.3                           0.81   \n",
      "1243                1.0        19.0                           0.91   \n",
      "\n",
      "      apache_4a_icu_death_prob  aids  cirrhosis  diabetes_mellitus  leukemia  \\\n",
      "5395                      0.03   0.0        0.0                1.0       0.0   \n",
      "1131                      0.21   0.0        0.0                0.0       0.0   \n",
      "1938                      0.15   0.0        0.0                1.0       0.0   \n",
      "6262                      0.00   0.0        0.0                0.0       0.0   \n",
      "2729                      0.03   0.0        0.0                0.0       0.0   \n",
      "...                        ...   ...        ...                ...       ...   \n",
      "2140                      0.33   0.0        0.0                0.0       0.0   \n",
      "6283                      0.02   1.0        0.0                0.0       0.0   \n",
      "2170                      0.10   0.0        0.0                1.0       0.0   \n",
      "3976                      0.70   0.0        0.0                0.0       0.0   \n",
      "1243                      0.84   0.0        0.0                0.0       0.0   \n",
      "\n",
      "      hospital_death  \n",
      "5395               0  \n",
      "1131               1  \n",
      "1938               1  \n",
      "6262               0  \n",
      "2729               0  \n",
      "...              ...  \n",
      "2140               1  \n",
      "6283               0  \n",
      "2170               1  \n",
      "3976               1  \n",
      "1243               1  \n",
      "\n",
      "[5440 rows x 30 columns]\n",
      "selected_features = ['pre_icu_los_days', 'glucose_apache', 'sodium_apache', 'heart_rate_apache', 'ventilated_apache', 'hospital_death']\n",
      "{'ventilated_apache <= 0.5': [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "forest = build_forest(training_data, n_trees, n_features, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD0v4Af4bM_T"
   },
   "source": [
    "### Step 4: Make predictions with the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "45zA7JFVbRLr"
   },
   "outputs": [],
   "source": [
    "def make_prediction_forest(forest, data):\n",
    "    \"\"\"\n",
    "    This function will use the pre-trained random forest to make the predictions\n",
    "    args:\n",
    "    * forest: the random forest\n",
    "    * data: the data used to predict\n",
    "    return:\n",
    "    * y_prediction: the predicted results\n",
    "    \"\"\"\n",
    "    y_prediction = []\n",
    "    predictions = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Loop through each tree in the forest\n",
    "    for i in forest:\n",
    "        # Call 'make_prediction'\n",
    "        pred = make_prediction(i, data)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Here, each tree has made its predictions.\n",
    "    # We can use majority vote in which the final prediction is determined by the mode (most frequent prediction) across all the trees.\n",
    "    # Feel free to use any other method to determine the final prediction\n",
    "\n",
    "    # Loop through each column of 'predictions'\n",
    "    predictions = np.array(predictions)\n",
    "    for i in range(predictions.shape[1]):\n",
    "        # For a specific column, find out each tree's prediction\n",
    "        column_predictions = predictions[:, i]\n",
    "        # Then, use a method to determine the final prediction for this column\n",
    "        # append the final prediction to y_prediction\n",
    "        count_dict = {}\n",
    "        for pred in column_predictions:\n",
    "            if pred in count_dict:\n",
    "                count_dict[pred] += 1\n",
    "            else:\n",
    "                count_dict[pred] = 1\n",
    "        #majority = max(count_dict, key = count_dict.get)\n",
    "        majority = int(training_data['hospital_death'].mode())\n",
    "        if 0 not in count_dict:\n",
    "            majority = 1\n",
    "        elif 1 not in count_dict:\n",
    "            majority = 0\n",
    "        elif count_dict[0] > count_dict[1]:\n",
    "            majority = 0\n",
    "        elif count_dict[1] > count_dict[0]:\n",
    "            majority = 1\n",
    "        y_prediction.append(majority)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXED6E837NRk"
   },
   "source": [
    "Validation (Optional)\n",
    "> If you split the data into training and validation sets in step 2, you can assess the accuracy of the forest here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "CsC39J9P7h-j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7434482758620691\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "pred_validation = make_prediction_forest(forest, x_validation)\n",
    "score = calculate_score(y_validation, pred_validation)\n",
    "print(score)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqp8xzDJTV6S"
   },
   "source": [
    "After you have completed fine-tuning and validating the forest, you can proceed to make predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "atRpa9KoPgNP"
   },
   "outputs": [],
   "source": [
    "y_pred_test = make_prediction_forest(forest, advanced_testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfLRewfzbjiZ"
   },
   "source": [
    "### Step 5: Write the Output File\n",
    "Save your predictions from the **random forest** in a csv file, named as **lab2_advanced.csv**\n",
    "> Note: Please do not touch the code in this step, we have made sure this outputs the correct file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "_H6MNjNmbst1"
   },
   "outputs": [],
   "source": [
    "advanced = []\n",
    "for i in range(len(y_pred_test)):\n",
    "    advanced.append(y_pred_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "7DHteTW7bvxz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hospital_death\n",
       "Id                 \n",
       "0                 1\n",
       "1                 1\n",
       "2                 1\n",
       "3                 1\n",
       "4                 1\n",
       "..              ...\n",
       "895               0\n",
       "896               0\n",
       "897               1\n",
       "898               0\n",
       "899               0\n",
       "\n",
       "[900 rows x 1 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_path = 'lab2_advanced.csv'\n",
    "\n",
    "advanced_df = pd.DataFrame({'Id': range(len(advanced)), 'hospital_death': advanced})\n",
    "advanced_df.set_index('Id', inplace=True)\n",
    "advanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "AZWdWt5fGPe9"
   },
   "outputs": [],
   "source": [
    "advanced_df.to_csv(advanced_path, header = True, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
